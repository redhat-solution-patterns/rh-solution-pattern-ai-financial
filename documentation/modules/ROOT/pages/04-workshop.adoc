= Solution Pattern: Name Template
:sectnums:
:sectlinks:
:doctype: book

= Workshop
During this workshop youwill learn how to:

- Get experience with a Weaviate enterprise installation.
- Learn how to use the Weaviate Python client.
- Learn how python application are deployed on Openshift
- Work with the Gradio library to build a user interface.
- Work with an LLM server on Openshift
- Understand the various components that make up a RAG solution

== Installing the workshop environment
=== Before getting started

==== Prequisites

- An OpenShift Cluster
  * Version 4.16 or greater
  * A worker node with a minimum of 4 CPUs, 16 GB of memory and 
  a single NVIDIA T4 GPU with 16GB of memory. (AWS `g4dn.xlarge` or equivalent)
  * The https://docs.openshift.com/container-platform/4.17/web_console/web_terminal/installing-web-terminal.html[web-terminal]
operator
- A client system with the following software installed:
  * https://mirror.openshift.com/pub/openshift-v4/clients/helm/latest[Helm]
  * https://maven.apache.org/download.cgi[Maven]
  * https://mirror.openshift.com/pub/openshift-v4/clients/ocp/latest/[The Openshift `oc` cli]
- An https://www.alphavantage.co/support/#api-key[AlphaVantage API Key] if you want to periodically 
refresh the stock symbol data.

=== Installing the environment

The following services on OpenShift are required:

==== Weaviate Vector Database

- `git clone https://github.com/redhat-na-ssa/demo-ai-weaviate`
- `cd demo-ai-weaviate`
- `oc apply -k deploy`

==== Ollama LLM Server

- `oc apply -k ollama/deploy`

Pull the necessary ML models:

Login to the Openshift console, open a terminal window in the `ollama` project
and run the following commands.

- `curl http://ollama.ollama/api/pull -d '{"model" : "all-minilm"}'`

- `curl http://ollama.ollama/api/pull -d '{"model" : "granite3-dense:8b"}'`

==== Stock Overview Ingestion Engine

===== Caching Proxy

Follow the instructions to install the caching proxy in the `camel` namespace.

- `oc new-project camel`
- `git clone https://github.com/joshdreagan/av-caching-proxy.git`
- `cd av-caching-proxy`
- `cp src/main/jkube/deployment.yml.template src/main/jkube/deployment.yml`
- `cp src/main/jkube/configmap.yml.template src/main/jkube/configmap.yml`
- `mvn -P openshift clean package oc:deploy`

The default values for `deployment.yml`, and `configmap.yml` should be fine. 

===== Stock Overview Syncronizer

Install the AlphaVantage syncronizer in the `camel` namespace. 

- `git clone https://github.com/joshdreagan/av-overview-sync.git`
- `cd av-overview-sync`
- `cp src/main/jkube/deployment.yml.template src/main/jkube/deployment.yml`
- `cp src/main/jkube/configmap.yml.template src/main/jkube/configmap.yml`
- `cp src/main/jkube/secret.yml.template src/main/jkube/secret.yml`
- `mvn -P openshift clean package oc:deploy`

Configure the `src/main/jkube/configmap.yml` to use the `all-minilm` vectorizer model 
and the `granite3-dense:8b` generative model.

Update your base64 encoded AlphaVantage API Key in the `src/main/jkube/secret.yml` file.

==== Gradio UI and application.

From a terminal, create an OpenShift application. 

[NOTE]
====
Obtain the 
https://raw.githubusercontent.com/redhat-na-ssa/demo-ai-weaviate/refs/heads/main/deploy/weaviate/configmap.yaml[Weaviate API key]
and use it to create the RAG application.
====

- `oc new-app python~https://github.com/redhat-na-ssa/demo-ai-weaviate --name rag --context-dir=/src --env WEAVIATE_API_KEY=your_weaviate_admin-api-key`

Expose the app with an external route and have fun.

- `oc create route edge --service rag --insecure-policy=Redirect`

=== Running the workshop

==== Understanding the Use case

Let's get started by having a look at the example
https://www.alphavantage.co/query?function=OVERVIEW&symbol=IBM&apikey=demo[IBM stock symbol json] to
explain the use case. Each json formatted data record includes the stock symbol, a company
name, a short description followed by a number of financial metrics. Imagine that you have been given 
this data and are asked to write up a financial summary. This sounds like a typical task that a financial
analyist may be asked to perform and at first glance seems straight forward but the data is not 
structured in a way that is easy to understand. Some of the data is represented as currency while 
others are represented as ratios, percentages, dates and so on. The task becomes more challenging and time 
consuming when more than one company must be analyzed not to mentioned that the data is semi-realtime
and could change several times day. This is where AI can help. In this workshop, we will make use of a vector
database and an LLM to give the analyst a head start on the task at hand.

==== Review the dataflow diagram to explain the workflow.
TODO

==== Review the architecture diagram to explain the Openshift services.
TODO

==== Run the RAG application.
TODO

  * Try different search terms and see how the results change.
  * Vary the limits and see the different number of returned results.
  * Try different LLM prompts.
